{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Practice of different models in huggingface"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RAG"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from transformers import RagTokenizer, RagRetriever, RagSequenceForGeneration"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Initialize model\n",
    "tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-sequence-nq\")\n",
    "retriever = RagRetriever.from_pretrained(\"facebook/rag-sequence-nq\", index_name=\"exact\", use_dummy_dataset=True)\n",
    "model = RagSequenceForGeneration.from_pretrained(\"facebook/rag-sequence-nq\", retriever = retriever)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Initialize data\n",
    "inputs = tokenizer([\"How many people live in Paris?\", 'how old are you?'], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "with tokenizer.as_target_tokenizer():\n",
    "   targets = tokenizer([\"In Paris, there are 10 million people.\", 'I am 22 years old.'], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "labels = targets[\"input_ids\"]\n",
    "print(input_ids.size())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([2, 9])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# 1. Encode\n",
    "question_hidden_states = model.question_encoder(input_ids)[0]\n",
    "print(question_hidden_states.size())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([2, 768])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# 2. Retrieve\n",
    "docs_dict = retriever(input_ids.numpy(), question_hidden_states.detach().numpy(), return_tensors=\"pt\")\n",
    "doc_scores = torch.bmm(question_hidden_states.unsqueeze(1), docs_dict[\"retrieved_doc_embeds\"].float().transpose(1, 2)).squeeze(1)\n",
    "print('question_hidden_states.unsqueeze(1)')\n",
    "print(question_hidden_states.unsqueeze(1).size())\n",
    "print('docs_dict[\"context_input_ids\"]')\n",
    "print(docs_dict['context_input_ids'].size())\n",
    "print('docs_dict[\"retrieved_doc_embeds\"].float().transpose(1, 2)')\n",
    "print(docs_dict[\"retrieved_doc_embeds\"].float().transpose(1, 2).size())\n",
    "print('doc_scores')\n",
    "print(doc_scores.size())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "question_hidden_states.unsqueeze(1)\n",
      "torch.Size([2, 1, 768])\n",
      "docs_dict[\"retrieved_doc_embeds\"].float().transpose(1, 2)\n",
      "torch.Size([2, 768, 5])\n",
      "doc_scores\n",
      "torch.Size([2, 5])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 3. Forward to generator\n",
    "outputs = model(context_input_ids=docs_dict[\"context_input_ids\"], context_attention_mask=docs_dict[\"context_attention_mask\"], doc_scores=doc_scores, decoder_input_ids=labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bert"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from transformers import BertTokenizer, BertModel"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Initialize model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Initialize data\n",
    "inputs = tokenizer([\"How many people live in Paris?\", 'how old are you?'], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "print(input_ids.size())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "outputs = model(**inputs, output_hidden_states=True)\n",
    "print(outputs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a = torch.rand((2,3))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "torch.cat((a, a))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('FWD': conda)"
  },
  "interpreter": {
   "hash": "5e687002bc60377ae87b855adfe470e827b4be244d7382e97081511de02b6558"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}