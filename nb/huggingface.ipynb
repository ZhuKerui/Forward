{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Practice of different models in huggingface"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RAG"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from transformers import RagTokenizer, RagRetriever, RagSequenceForGeneration"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Initialize model\n",
    "tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-sequence-nq\")\n",
    "retriever = RagRetriever.from_pretrained(\"facebook/rag-sequence-nq\", index_name=\"exact\", use_dummy_dataset=True)\n",
    "model = RagSequenceForGeneration.from_pretrained(\"facebook/rag-sequence-nq\", retriever = retriever)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Initialize data\n",
    "inputs = tokenizer([\"How many people live in Paris?\", 'how old are you?'], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "with tokenizer.as_target_tokenizer():\n",
    "   targets = tokenizer([\"In Paris, there are 10 million people.\", 'I am 22 years old.'], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "labels = targets[\"input_ids\"]\n",
    "print(input_ids.size())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 1. Encode\n",
    "question_hidden_states = model.question_encoder(input_ids)[0]\n",
    "print(question_hidden_states.size())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 2. Retrieve\n",
    "docs_dict = retriever(input_ids.numpy(), question_hidden_states.detach().numpy(), return_tensors=\"pt\")\n",
    "doc_scores = torch.bmm(question_hidden_states.unsqueeze(1), docs_dict[\"retrieved_doc_embeds\"].float().transpose(1, 2)).squeeze(1)\n",
    "print(doc_scores.size())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 3. Forward to generator\n",
    "outputs = model(context_input_ids=docs_dict[\"context_input_ids\"], context_attention_mask=docs_dict[\"context_attention_mask\"], doc_scores=doc_scores, decoder_input_ids=labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bert"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from transformers import BertTokenizer, BertModel"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Initialize model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Initialize data\n",
    "inputs = tokenizer([\"How many people live in Paris?\", 'how old are you?'], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "print(input_ids.size())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([2, 9])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "outputs = model(**inputs, output_hidden_states=True)\n",
    "print(outputs)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.2846,  0.2654,  0.0621,  ..., -0.5076,  0.4604,  0.4020],\n",
      "         [ 0.5797, -0.0389, -0.1691,  ..., -0.2428,  0.4190,  0.2785],\n",
      "         [ 0.3598, -0.6328,  0.5946,  ..., -0.6814,  0.5046,  0.0212],\n",
      "         ...,\n",
      "         [ 0.6149, -0.3343, -0.1552,  ..., -0.8227, -0.4112, -0.0663],\n",
      "         [ 0.0534, -0.3793, -1.0612,  ..., -0.0713,  0.6246, -0.3960],\n",
      "         [ 0.7939,  0.0290, -0.2404,  ...,  0.0031, -0.5633, -0.2443]],\n",
      "\n",
      "        [[ 0.1435,  0.2915, -0.1897,  ..., -0.2568,  0.2299,  0.2998],\n",
      "         [ 0.8528,  0.2125,  0.2806,  ...,  0.0611,  0.3585,  0.3833],\n",
      "         [ 0.6508,  0.4176,  0.7111,  ..., -0.6729,  0.3827, -1.2437],\n",
      "         ...,\n",
      "         [ 0.8221,  0.0168, -0.1774,  ...,  0.1684, -0.5292, -0.2830],\n",
      "         [ 0.0785,  0.4297,  0.4029,  ...,  0.0484,  0.1668, -0.2065],\n",
      "         [-0.1175,  0.2349,  0.1610,  ...,  0.3380,  0.1549, -0.0944]]],\n",
      "       grad_fn=<NativeLayerNormBackward>), pooler_output=tensor([[-0.8817, -0.4173, -0.5866,  ..., -0.2659, -0.6855,  0.9059],\n",
      "        [-0.9105, -0.4678, -0.6888,  ..., -0.4632, -0.7705,  0.9395]],\n",
      "       grad_fn=<TanhBackward>), hidden_states=(tensor([[[ 1.6855e-01, -2.8577e-01, -3.2613e-01,  ..., -2.7571e-02,\n",
      "           3.8253e-02,  1.6400e-01],\n",
      "         [-7.1995e-02,  9.1082e-01, -1.1910e+00,  ...,  7.3999e-01,\n",
      "           8.6135e-01,  2.1739e-01],\n",
      "         [-3.8335e-01,  5.7160e-01, -2.2298e-01,  ...,  3.7527e-01,\n",
      "          -3.4120e-01, -4.7738e-01],\n",
      "         ...,\n",
      "         [ 7.1628e-02, -9.7562e-01, -4.1565e-01,  ..., -1.4641e-01,\n",
      "          -4.3677e-01, -4.1532e-01],\n",
      "         [ 5.0234e-01, -3.8782e-01, -3.1277e-01,  ...,  2.1256e-01,\n",
      "           7.5651e-01,  5.4777e-01],\n",
      "         [-2.3061e-01, -2.4164e-01, -4.0893e-02,  ..., -2.8555e-01,\n",
      "           2.4370e-01, -7.0539e-02]],\n",
      "\n",
      "        [[ 1.6855e-01, -2.8577e-01, -3.2613e-01,  ..., -2.7571e-02,\n",
      "           3.8253e-02,  1.6400e-01],\n",
      "         [-7.1995e-02,  9.1082e-01, -1.1910e+00,  ...,  7.3999e-01,\n",
      "           8.6135e-01,  2.1739e-01],\n",
      "         [-2.3349e-01,  7.4292e-01, -6.1086e-03,  ...,  3.1936e-01,\n",
      "           8.3416e-02, -6.4926e-01],\n",
      "         ...,\n",
      "         [-1.4815e-01, -2.9485e-01, -1.6900e-01,  ..., -5.0090e-01,\n",
      "           2.5442e-01, -7.0021e-02],\n",
      "         [ 2.4668e-01, -8.4544e-01, -1.1325e-01,  ...,  2.6934e-04,\n",
      "          -1.1196e-02,  1.5729e-01],\n",
      "         [ 2.7045e-01, -8.1214e-01, -2.3954e-01,  ...,  1.5099e-01,\n",
      "          -1.1404e-01,  1.9319e-01]]], grad_fn=<NativeLayerNormBackward>), tensor([[[ 7.6040e-02,  1.2417e-01, -1.6491e-01,  ...,  7.1000e-02,\n",
      "           7.3523e-02,  5.5196e-03],\n",
      "         [-6.0642e-02,  1.3876e+00, -9.5484e-01,  ..., -5.0425e-02,\n",
      "           3.0609e-01,  6.9665e-01],\n",
      "         [ 2.7962e-01,  1.0400e+00,  6.0151e-03,  ..., -2.7121e-01,\n",
      "          -6.1583e-01, -1.8871e-01],\n",
      "         ...,\n",
      "         [ 6.1598e-01, -1.2795e+00, -1.0374e+00,  ..., -5.0023e-01,\n",
      "          -7.1372e-01, -6.5549e-01],\n",
      "         [ 5.6749e-01, -5.8608e-01, -6.7222e-01,  ..., -1.9535e-03,\n",
      "           9.9768e-01,  9.1824e-01],\n",
      "         [ 1.1588e-03, -9.8350e-02,  5.5609e-03,  ..., -3.5949e-01,\n",
      "           3.9212e-01,  1.3274e-01]],\n",
      "\n",
      "        [[ 3.9956e-02,  1.1228e-01, -1.6143e-01,  ...,  9.7595e-02,\n",
      "           4.1314e-02, -2.3850e-02],\n",
      "         [ 1.0294e-01,  1.4660e+00, -1.2248e+00,  ...,  2.2719e-01,\n",
      "           5.6719e-01,  5.8033e-01],\n",
      "         [ 1.6536e-01,  1.1234e+00, -3.8618e-01,  ...,  1.7510e-01,\n",
      "           3.8551e-01, -1.0474e+00],\n",
      "         ...,\n",
      "         [ 1.0386e-01, -2.3815e-01, -9.9289e-02,  ..., -5.6913e-01,\n",
      "           3.1298e-01,  6.3228e-03],\n",
      "         [ 7.9746e-02, -5.7024e-01,  3.9708e-01,  ...,  3.3998e-01,\n",
      "          -9.3698e-02, -3.2276e-01],\n",
      "         [ 6.3130e-02, -5.8583e-01,  2.9845e-01,  ...,  3.8847e-01,\n",
      "          -1.2914e-01, -3.1572e-01]]], grad_fn=<NativeLayerNormBackward>), tensor([[[-5.3833e-02, -2.3045e-01, -3.5456e-01,  ...,  1.7075e-01,\n",
      "           8.4360e-02, -2.8052e-02],\n",
      "         [ 1.8894e-01,  1.7815e+00, -2.5557e-01,  ...,  5.4309e-02,\n",
      "           1.4090e-03,  4.7386e-01],\n",
      "         [ 5.7794e-01,  6.8784e-01,  9.0931e-01,  ..., -8.3813e-03,\n",
      "          -5.2344e-01, -2.9439e-01],\n",
      "         ...,\n",
      "         [ 6.9721e-01, -4.9630e-01, -1.0003e+00,  ..., -8.0790e-01,\n",
      "          -9.1501e-01, -6.6785e-01],\n",
      "         [ 4.9216e-01, -8.2416e-01, -5.8591e-01,  ..., -1.7296e-01,\n",
      "           8.7596e-01,  8.9961e-01],\n",
      "         [-1.4685e-01, -1.8590e-01,  1.0658e-01,  ..., -6.7144e-02,\n",
      "           3.1905e-01, -1.1354e-01]],\n",
      "\n",
      "        [[-9.6392e-02, -1.9945e-01, -3.3544e-01,  ...,  2.0598e-01,\n",
      "           1.5415e-01,  5.5842e-02],\n",
      "         [ 2.5825e-01,  1.8353e+00, -5.7336e-01,  ...,  3.2668e-01,\n",
      "           1.7316e-01,  5.0600e-01],\n",
      "         [ 1.9100e-01,  1.5171e+00, -3.0890e-02,  ...,  5.8115e-01,\n",
      "           3.8514e-01, -1.1800e+00],\n",
      "         ...,\n",
      "         [-6.7651e-02, -2.8305e-01,  1.0606e-01,  ..., -2.4952e-01,\n",
      "           3.6193e-01, -1.7078e-01],\n",
      "         [ 1.7041e-01, -4.1926e-01,  7.5536e-02,  ...,  9.3672e-01,\n",
      "          -3.2313e-01, -4.1815e-01],\n",
      "         [-1.5229e-01, -4.6947e-01, -4.0410e-02,  ...,  9.2708e-01,\n",
      "          -2.8536e-01, -4.0263e-01]]], grad_fn=<NativeLayerNormBackward>), tensor([[[ 0.0115, -0.3528, -0.1762,  ...,  0.1269,  0.1443,  0.1079],\n",
      "         [ 0.1624,  1.1752,  0.3550,  ...,  0.1723, -0.6211,  0.7193],\n",
      "         [ 1.1425,  0.3931,  1.2628,  ..., -0.8289, -0.4390, -0.2565],\n",
      "         ...,\n",
      "         [ 0.9416, -0.5909, -1.1458,  ..., -0.9195, -1.0269, -1.0466],\n",
      "         [ 0.4634, -0.9101, -0.1913,  ...,  0.0444,  0.3963,  0.1106],\n",
      "         [-0.0709, -0.1101,  0.1197,  ...,  0.0276,  0.0555, -0.0332]],\n",
      "\n",
      "        [[-0.0643, -0.3263, -0.1078,  ...,  0.2505,  0.1643,  0.2055],\n",
      "         [ 0.3074,  1.9050, -0.1761,  ...,  0.3258, -0.5939,  1.0418],\n",
      "         [ 0.5878,  1.5367, -0.0733,  ...,  0.3960,  0.4874, -1.6610],\n",
      "         ...,\n",
      "         [-0.0595, -0.1266,  0.1223,  ...,  0.0112,  0.0632, -0.0260],\n",
      "         [-0.1424, -0.2649,  0.4293,  ...,  1.0977, -0.0620, -0.3849],\n",
      "         [-0.5106, -0.3225,  0.3259,  ...,  1.0553,  0.0288, -0.4693]]],\n",
      "       grad_fn=<NativeLayerNormBackward>), tensor([[[ 0.2560, -0.6953, -0.7631,  ...,  0.3738,  0.1211,  0.4460],\n",
      "         [ 0.6317,  0.5913,  0.1278,  ...,  0.6090, -0.6862,  0.4406],\n",
      "         [ 0.6366, -0.0328,  0.8114,  ..., -0.7282, -0.5686, -0.2180],\n",
      "         ...,\n",
      "         [ 0.9780, -0.6935, -1.2523,  ..., -0.2971, -1.1251, -0.6496],\n",
      "         [ 0.9062, -1.2560, -0.4409,  ...,  0.2230,  0.2306,  0.5061],\n",
      "         [-0.0199, -0.0568,  0.0078,  ...,  0.0156,  0.0491, -0.0402]],\n",
      "\n",
      "        [[ 0.0980, -0.6141, -0.6927,  ...,  0.3958,  0.0689,  0.5371],\n",
      "         [ 0.7484,  1.2771,  0.2076,  ...,  0.1676, -0.7688,  0.2441],\n",
      "         [ 0.6642,  1.6276,  0.2206,  ...,  0.3161, -0.3414, -1.8692],\n",
      "         ...,\n",
      "         [-0.0247, -0.0611,  0.0061,  ...,  0.0139,  0.0497, -0.0359],\n",
      "         [ 0.0766, -0.5992,  0.7119,  ...,  0.8317, -0.1246, -0.4312],\n",
      "         [-0.4403, -0.7263,  0.5664,  ...,  0.5931, -0.1145, -0.1910]]],\n",
      "       grad_fn=<NativeLayerNormBackward>), tensor([[[ 1.4695e-01, -5.8133e-01, -5.6778e-01,  ..., -8.6889e-02,\n",
      "           1.6783e-01,  4.6381e-01],\n",
      "         [ 1.0186e+00,  7.4139e-02,  3.0555e-01,  ...,  3.3898e-01,\n",
      "          -7.6072e-01,  6.3341e-01],\n",
      "         [ 7.1795e-01, -1.1686e-01,  4.3608e-01,  ..., -5.0084e-01,\n",
      "          -5.1177e-01, -3.9563e-02],\n",
      "         ...,\n",
      "         [ 1.0273e+00, -5.4636e-01, -9.3096e-01,  ..., -2.8640e-01,\n",
      "          -1.1904e+00, -7.0102e-01],\n",
      "         [ 5.4701e-01, -9.0352e-01, -2.5711e-01,  ..., -7.0204e-02,\n",
      "          -1.5711e-01,  7.3995e-01],\n",
      "         [-1.6898e-02, -3.8645e-02,  1.7057e-02,  ...,  1.9127e-02,\n",
      "           1.9560e-03, -4.0443e-02]],\n",
      "\n",
      "        [[ 4.5650e-02, -3.1635e-01, -5.0394e-01,  ..., -1.5260e-01,\n",
      "           3.5177e-01,  4.7118e-01],\n",
      "         [ 1.1468e+00,  9.3316e-01,  4.1691e-01,  ..., -3.4588e-01,\n",
      "          -1.2873e+00,  8.0792e-01],\n",
      "         [ 6.3288e-01,  1.7669e+00,  1.0043e-01,  ...,  6.6889e-02,\n",
      "          -2.0379e-01, -2.2096e+00],\n",
      "         ...,\n",
      "         [-1.7532e-02, -4.2189e-02,  1.5049e-02,  ...,  1.8185e-02,\n",
      "           7.4693e-03, -3.4109e-02],\n",
      "         [ 3.4004e-01, -3.6148e-01,  7.9459e-01,  ..., -1.8767e-01,\n",
      "          -1.5710e-01, -1.7331e-01],\n",
      "         [-1.8488e-01, -2.4181e-01,  8.6963e-01,  ..., -4.1769e-01,\n",
      "          -3.4693e-02,  3.2420e-01]]], grad_fn=<NativeLayerNormBackward>), tensor([[[ 0.3103, -0.6985, -0.4817,  ..., -0.3661,  0.1384,  0.4416],\n",
      "         [ 1.6622, -0.1429, -0.1825,  ...,  0.2531, -1.0472,  0.3355],\n",
      "         [ 0.9957, -0.4173,  0.1239,  ..., -0.4903, -0.3457,  0.2469],\n",
      "         ...,\n",
      "         [ 1.0586, -0.6683, -0.8202,  ...,  0.0075, -0.7760, -0.7704],\n",
      "         [ 0.4427, -0.9937, -0.9235,  ..., -0.8836, -0.6058,  0.7699],\n",
      "         [ 0.0170, -0.0325, -0.0185,  ...,  0.0022, -0.0201, -0.0436]],\n",
      "\n",
      "        [[ 0.0766, -0.8025, -0.5984,  ..., -0.1910,  0.3450,  0.4047],\n",
      "         [ 1.2388,  0.3218, -0.1078,  ..., -0.3403, -1.5485,  0.6676],\n",
      "         [ 0.5078,  1.2636,  0.3732,  ..., -0.0048, -0.1278, -1.9847],\n",
      "         ...,\n",
      "         [ 0.0131, -0.0368, -0.0216,  ...,  0.0028, -0.0144, -0.0444],\n",
      "         [ 0.2957, -0.1167,  0.8074,  ...,  0.0243, -0.4093, -0.3233],\n",
      "         [-0.3605, -0.1573,  0.7114,  ..., -0.1813, -0.4359,  0.2594]]],\n",
      "       grad_fn=<NativeLayerNormBackward>), tensor([[[ 0.2953, -0.0695, -0.4655,  ..., -1.0481,  0.4699,  0.6480],\n",
      "         [ 1.6094,  0.0430, -0.1819,  ..., -0.0219, -1.0286,  0.1676],\n",
      "         [ 1.2120, -0.5320, -0.2269,  ..., -0.4481, -0.0985,  0.4060],\n",
      "         ...,\n",
      "         [ 1.3069, -0.8417, -0.8223,  ..., -0.3376, -0.4168, -0.4800],\n",
      "         [ 0.3527, -1.4289, -1.7454,  ..., -1.0602, -0.2840,  1.2910],\n",
      "         [-0.0066, -0.0294, -0.0219,  ..., -0.0278,  0.0178, -0.0523]],\n",
      "\n",
      "        [[ 0.2725, -0.3489, -0.6476,  ..., -0.5770,  0.5054,  0.7303],\n",
      "         [ 1.2741,  0.5357,  0.1693,  ..., -0.0595, -1.1799,  0.8370],\n",
      "         [ 0.2485,  1.3303,  0.6413,  ...,  0.6227,  0.7714, -1.8550],\n",
      "         ...,\n",
      "         [-0.0103, -0.0386, -0.0204,  ..., -0.0218,  0.0166, -0.0559],\n",
      "         [ 0.2425,  0.3416,  0.7714,  ...,  0.3788, -0.2448,  0.1916],\n",
      "         [-0.5025, -0.0281,  0.1117,  ...,  0.0618, -0.3359,  0.8430]]],\n",
      "       grad_fn=<NativeLayerNormBackward>), tensor([[[ 0.3973,  0.0293, -1.0531,  ..., -1.1913,  0.5208,  0.9913],\n",
      "         [ 1.6217, -0.6570, -0.3843,  ..., -0.6253, -0.5376,  0.3354],\n",
      "         [ 1.1180, -0.9818, -0.4635,  ..., -0.6287,  0.6531,  0.6563],\n",
      "         ...,\n",
      "         [ 1.0192, -0.5675, -0.7477,  ..., -0.5711, -0.2624, -0.2492],\n",
      "         [-0.2573, -1.5305, -1.7140,  ..., -1.1924, -0.6891,  0.9176],\n",
      "         [ 0.0205, -0.0155,  0.0190,  ..., -0.0519, -0.0151, -0.0802]],\n",
      "\n",
      "        [[ 0.0696, -0.2591, -1.1843,  ..., -0.7818,  0.2836,  1.0111],\n",
      "         [ 1.1514, -0.1780,  0.0639,  ..., -0.2278, -0.8296,  0.9061],\n",
      "         [ 0.5809,  0.3568,  0.2194,  ..., -0.2653,  0.4779, -1.8712],\n",
      "         ...,\n",
      "         [ 0.0170, -0.0157,  0.0306,  ..., -0.0453, -0.0266, -0.0769],\n",
      "         [ 0.3079,  0.4504,  0.8898,  ...,  0.3100, -0.2048,  0.2494],\n",
      "         [-0.6266,  0.2297,  0.1159,  ..., -0.0495, -0.6888,  0.7489]]],\n",
      "       grad_fn=<NativeLayerNormBackward>), tensor([[[ 0.5043,  0.1244, -1.3431,  ..., -0.6781,  0.6212,  0.4092],\n",
      "         [ 1.3946, -0.7899, -0.3520,  ..., -0.5566, -0.4262, -0.1244],\n",
      "         [ 0.9465, -1.0719, -0.4233,  ..., -0.6189,  0.8777, -0.0156],\n",
      "         ...,\n",
      "         [ 0.8374, -0.6089, -0.3715,  ..., -0.7320,  0.1552, -0.0930],\n",
      "         [-0.6773, -1.4474, -1.9202,  ..., -1.1061, -0.0415, -0.4180],\n",
      "         [ 0.0251, -0.0087,  0.0154,  ..., -0.0838, -0.0371, -0.0811]],\n",
      "\n",
      "        [[-0.0749,  0.0811, -1.5761,  ..., -0.3669,  0.2366,  0.4526],\n",
      "         [ 1.1097, -0.3698,  0.1258,  ..., -0.1537, -0.4967,  0.5525],\n",
      "         [ 0.7321,  0.3124,  0.2077,  ..., -0.5790,  0.7837, -1.7493],\n",
      "         ...,\n",
      "         [ 0.0156,  0.0083,  0.0159,  ..., -0.0599, -0.0560, -0.0263],\n",
      "         [ 0.2712,  0.7779,  0.6655,  ...,  0.1972, -0.0080, -0.0899],\n",
      "         [-0.6508,  0.2782, -0.3437,  ..., -0.0493, -0.3541,  0.2790]]],\n",
      "       grad_fn=<NativeLayerNormBackward>), tensor([[[ 0.8184,  0.1690, -0.6817,  ..., -0.7419,  0.1015,  0.2053],\n",
      "         [ 0.9182, -0.4305, -0.3055,  ..., -0.5551, -0.5474, -0.5677],\n",
      "         [ 0.5602, -1.3647, -0.3122,  ..., -0.8615,  0.9184, -0.2197],\n",
      "         ...,\n",
      "         [ 0.5867, -0.5669, -0.4071,  ..., -0.9069, -0.1050, -0.3258],\n",
      "         [-0.5286, -0.9736, -1.6888,  ..., -0.7172,  0.0833, -0.4471],\n",
      "         [ 0.0034,  0.0204, -0.0051,  ...,  0.0806, -0.0289, -0.0309]],\n",
      "\n",
      "        [[ 0.1662,  0.2277, -0.6240,  ..., -0.4758, -0.4437,  0.3206],\n",
      "         [ 1.4148, -0.1468,  0.2092,  ..., -0.6470, -0.6882,  0.1467],\n",
      "         [ 0.7078, -0.1137,  0.4492,  ..., -0.9231,  0.3970, -1.8039],\n",
      "         ...,\n",
      "         [ 0.0286,  0.0277,  0.0378,  ...,  0.0813, -0.0643, -0.0143],\n",
      "         [ 0.0032,  1.0019,  0.6651,  ..., -0.0168, -0.1514, -0.3609],\n",
      "         [-0.7480,  0.3587,  0.0208,  ...,  0.0274, -0.5389,  0.3471]]],\n",
      "       grad_fn=<NativeLayerNormBackward>), tensor([[[ 0.4741, -0.1780, -0.2074,  ..., -0.6052,  0.3163,  0.0464],\n",
      "         [ 0.6600, -0.4162, -0.5826,  ..., -0.7886, -0.0207, -0.0170],\n",
      "         [ 0.2026, -1.1068, -0.1591,  ..., -0.9627,  0.7917,  0.1114],\n",
      "         ...,\n",
      "         [ 0.6562, -0.3426, -0.5260,  ..., -0.8263, -0.1394, -0.0860],\n",
      "         [-0.3274, -0.7746, -1.1503,  ..., -0.5425,  0.4356, -0.4472],\n",
      "         [ 0.0429,  0.0129, -0.0367,  ...,  0.0272, -0.0449,  0.0238]],\n",
      "\n",
      "        [[ 0.1551,  0.0363, -0.3356,  ..., -0.3993, -0.0708,  0.0485],\n",
      "         [ 1.1919, -0.1653,  0.1301,  ..., -0.8273, -0.1990,  0.3078],\n",
      "         [ 0.5140, -0.0921,  0.3991,  ..., -0.9564,  0.5736, -1.4888],\n",
      "         ...,\n",
      "         [ 0.0232,  0.0019, -0.0313,  ...,  0.0203, -0.0466,  0.0101],\n",
      "         [ 0.0973,  0.6990,  0.6698,  ..., -0.3946, -0.0839, -0.4361],\n",
      "         [-0.4216,  0.2582,  0.1179,  ..., -0.1898, -0.3335,  0.1030]]],\n",
      "       grad_fn=<NativeLayerNormBackward>), tensor([[[ 0.2846,  0.2654,  0.0621,  ..., -0.5076,  0.4604,  0.4020],\n",
      "         [ 0.5797, -0.0389, -0.1691,  ..., -0.2428,  0.4190,  0.2785],\n",
      "         [ 0.3598, -0.6328,  0.5946,  ..., -0.6814,  0.5046,  0.0212],\n",
      "         ...,\n",
      "         [ 0.6149, -0.3343, -0.1552,  ..., -0.8227, -0.4112, -0.0663],\n",
      "         [ 0.0534, -0.3793, -1.0612,  ..., -0.0713,  0.6246, -0.3960],\n",
      "         [ 0.7939,  0.0290, -0.2404,  ...,  0.0031, -0.5633, -0.2443]],\n",
      "\n",
      "        [[ 0.1435,  0.2915, -0.1897,  ..., -0.2568,  0.2299,  0.2998],\n",
      "         [ 0.8528,  0.2125,  0.2806,  ...,  0.0611,  0.3585,  0.3833],\n",
      "         [ 0.6508,  0.4176,  0.7111,  ..., -0.6729,  0.3827, -1.2437],\n",
      "         ...,\n",
      "         [ 0.8221,  0.0168, -0.1774,  ...,  0.1684, -0.5292, -0.2830],\n",
      "         [ 0.0785,  0.4297,  0.4029,  ...,  0.0484,  0.1668, -0.2065],\n",
      "         [-0.1175,  0.2349,  0.1610,  ...,  0.3380,  0.1549, -0.0944]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)), past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "a = torch.rand((2,3))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "torch.cat((a, a))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.1035, 0.5856, 0.9475],\n",
       "        [0.0679, 0.0193, 0.4326],\n",
       "        [0.1035, 0.5856, 0.9475],\n",
       "        [0.0679, 0.0193, 0.4326]])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('FWD': conda)"
  },
  "interpreter": {
   "hash": "5e687002bc60377ae87b855adfe470e827b4be244d7382e97081511de02b6558"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}