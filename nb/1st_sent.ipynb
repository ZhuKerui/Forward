{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Train Score Function Using 1st Sentences in Wikipedia Page"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BatchEncoding, AdamW\n",
    "import torch\n",
    "from typing import List\n",
    "import tqdm\n",
    "from torch.nn import Softmax\n",
    "import numpy as np\n",
    "import csv\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "\n",
    "sys.path.append('..')\n",
    "from tools.BasicUtils import my_read, my_json_read, my_csv_read, my_write, batch\n",
    "from tools.TextProcessing import clean_text, sent_lemmatize\n",
    "from tools.DocProcessing import CoOccurrence"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Update readme.txt"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "file_description = [\n",
    "    \"wiki_cs_ent.txt ---- CS wikipedia entities from data/kw_ent_map.json which have records in 1st-sents-new.json\",\n",
    "    \"*.pt ---- Training result\",\n",
    "    \"train.csv ---- The training dataset\",\n",
    "    \"valid.csv ---- The validation dataset\",\n",
    "    \"wrong_prediction.tsv ---- The sentences that are wrongly predicted by the model\"\n",
    "]\n",
    "\n",
    "if not os.path.exists('../data/temp/1st_sent'):\n",
    "    os.mkdir('../data/temp/1st_sent')\n",
    "    \n",
    "my_write('../data/temp/1st_sent/readme.txt', file_description)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load two main data files: 1st-sents-new.json and kw_ent_map.json"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load 1st-sents-new.json with all words lower-cased\n",
    "first_sents_dict = json.loads(open('../data/raw_data/1st-sents-new.json', 'r').read().lower())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load kw_ent_map.json\n",
    "kw_ent_map = my_json_read('../data/corpus/kw_ent_map.json')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Collect CS Wikipedia entities that have records in 1st-sents-new.json"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get cs terms that have wikipedia page\n",
    "wiki_cs_ent_in_1st = [item.lower() for item in set(kw_ent_map.values()) if item.lower() in first_sents_dict]\n",
    "my_write('../data/temp/1st_sent/wiki_cs_ent.txt', wiki_cs_ent_in_1st)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Collect dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "wiki_cs_ent_in_1st = my_read('../data/temp/1st_sent/wiki_cs_ent.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "wiki_pages = my_json_read('../data/corpus/wiki_pages.json')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Collect negative sentences\n",
    "remove_list = ['See also', 'References', 'Further reading', 'summary', 'title']\n",
    "\n",
    "def collect_neg_sents_from_term(dic:dict, n:int=5):\n",
    "    term = clean_text(dic['title'])\n",
    "    neg_sents = []\n",
    "    section_list = list(dic.keys())\n",
    "    while len(neg_sents) < n and len(section_list) != 0:\n",
    "        section = section_list.pop()\n",
    "        if section in remove_list:\n",
    "            continue\n",
    "        section_text = dic[section]\n",
    "        if not section_text:\n",
    "            continue\n",
    "        processed_text = clean_text(section_text)\n",
    "        if term not in processed_text:\n",
    "            continue\n",
    "        temp_sents = sent_tokenize(processed_text)\n",
    "        for sent in temp_sents:\n",
    "            if term in sent:\n",
    "                neg_sents.append('%s\\t%s' % (term, sent))\n",
    "    return neg_sents if neg_sents else None\n",
    "\n",
    "neg_sents = []\n",
    "for dic in wiki_pages:\n",
    "    temp = collect_neg_sents_from_term(dic)\n",
    "    if temp:\n",
    "        neg_sents += temp\n",
    "\n",
    "my_write('../data/test/neg_sents.txt', neg_sents)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Collect positive sentences\n",
    "my_write('../data/test/pos_sents.txt', ['%s\\t%s' % (clean_text(term), clean_text(first_sents_dict[term]['sentence'])) for term in wiki_cs_ent_in_1st])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "o = CoOccurrence('../data/corpus/wordtree.json')\n",
    "o.line_operation(sent_lemmatize('a hidden markov model is a markov chain for which the state is only partially observable.'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Generate positive samples\n",
    "r = my_csv_read('../data/test/pos_sents.txt', delimiter='\\t')\n",
    "target_list = []\n",
    "for item in r:\n",
    "    reformed_list = sent_lemmatize(item[1])\n",
    "    reformed_sent = ' '.join(reformed_list)\n",
    "    temp_kw_set = o.line_operation(reformed_list)\n",
    "    if temp_kw_set is None:\n",
    "        continue\n",
    "    if len(temp_kw_set) < 2:\n",
    "        continue\n",
    "    if item[0] not in temp_kw_set:\n",
    "        continue\n",
    "    temp_kw_set.remove(item[0])\n",
    "    for kw in temp_kw_set:\n",
    "        target_list.append((item[0], kw, reformed_sent))\n",
    "        target_list.append((kw, item[0], reformed_sent))\n",
    "with open('../data/test/pos_samples.tsv', 'w') as f_out:\n",
    "    w = csv.writer(f_out, delimiter='\\t')\n",
    "    w.writerows(target_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Generate negative samples\n",
    "neg = my_csv_read('../data/test/neg_sents.txt', delimiter='\\t')\n",
    "pos = my_csv_read('../data/test/pos_sents.txt', delimiter='\\t')\n",
    "keyword_list = my_read('../data/corpus/keyword_f.txt')\n",
    "target_list = []\n",
    "\n",
    "for item in pos:\n",
    "    reformed_list = sent_lemmatize(item[1])\n",
    "    reformed_sent = ' '.join(reformed_list)\n",
    "    temp_kw_set = o.line_operation(reformed_list)\n",
    "    if temp_kw_set is None:\n",
    "        continue\n",
    "    random_false_kw = random.sample(keyword_list, 1)[0]\n",
    "    random_true_kw = random.sample(temp_kw_set, 1)[0]\n",
    "    target_list.append((random_false_kw, random_true_kw, reformed_sent))\n",
    "    target_list.append((random_true_kw, random_false_kw, reformed_sent))\n",
    "\n",
    "for i, item in enumerate(neg):\n",
    "    reformed_list = sent_lemmatize(item[1])\n",
    "    reformed_sent = ' '.join(reformed_list)\n",
    "    temp_kw_set = o.line_operation(reformed_list)\n",
    "    if temp_kw_set is None:\n",
    "        continue\n",
    "    if len(temp_kw_set) < 2:\n",
    "        continue\n",
    "    if item[0] not in temp_kw_set:\n",
    "        continue\n",
    "    temp_kw_set.remove(item[0])\n",
    "    for kw in temp_kw_set:\n",
    "        target_list.append((item[0], kw, reformed_sent))\n",
    "        target_list.append((kw, item[0], reformed_sent))\n",
    "    if i >= 10000:\n",
    "        break\n",
    "with open('../data/test/neg_samples.tsv', 'w') as f_out:\n",
    "    w = csv.writer(f_out, delimiter='\\t')\n",
    "    w.writerows(target_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Generate training data\n",
    "\n",
    "# # Positive samples\n",
    "pos = pd.DataFrame(my_csv_read('../data/test/pos_samples.tsv', delimiter='\\t'), columns=['head_ent', 'tail_ent', 'sent'])\n",
    "pos['label'] = 'T'\n",
    "\n",
    "# Negative samples 1\n",
    "neg = pd.DataFrame(my_csv_read('../data/test/neg_samples.tsv', delimiter='\\t'), columns=['head_ent', 'tail_ent', 'sent'])\n",
    "neg['label'] = 'F'\n",
    "\n",
    "\n",
    "# df = pos.append(neg, ignore_index=True).sample(frac=1.0).reset_index(drop=True)\n",
    "df = pd.concat([pos, neg], axis=0, ignore_index=True).sample(frac=1.0).reset_index(drop=True)\n",
    "df['pair'] = df.apply(lambda x: '<HEAD_ENT> %s <TAIL_ENT> %s' % (x.head_ent, x.tail_ent), axis=1)\n",
    "\n",
    "split_line = int(len(df) * 0.8)\n",
    "train_df = df[:split_line].reset_index(drop=True)\n",
    "valid_df = df[split_line:].reset_index(drop=True)\n",
    "\n",
    "train_df.to_csv('../data/temp/1st_sent/train.csv', index=False)\n",
    "valid_df.to_csv('../data/temp/1st_sent/valid.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load training and validation data\n",
    "train_df = pd.read_csv('../data/temp/1st_sent/train.csv')\n",
    "valid_df = pd.read_csv('../data/temp/1st_sent/valid.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenizer.add_special_tokens({'additional_special_tokens' : ['<HEAD_ENT>', '<TAIL_ENT>', '<DEP_PATH>']})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "torch.cuda.is_available()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load model for training\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "# model = BertForSequenceClassification.from_pretrained('temp2.pt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Train the model\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "batch_list = [item for item in batch(train_df, 32)]\n",
    "\n",
    "for epoch in range(3):\n",
    "    loss = 0\n",
    "    batch_num = 0\n",
    "    for batch_df in tqdm.tqdm(batch_list):\n",
    "        optim.zero_grad()\n",
    "        labels = torch.tensor([1 if i == 'T' else 0 for i in batch_df.label.to_list()]).unsqueeze(1).to(device)\n",
    "        inputs = BatchEncoding(tokenizer(batch_df.sent.to_list(), batch_df.pair.to_list(), padding=True, truncation=True, max_length=80, return_tensors=\"pt\")).to(device)\n",
    "        output = model(**inputs, labels=labels)\n",
    "        loss += output.loss\n",
    "        output.loss.backward()\n",
    "        optim.step()\n",
    "    print(loss / len(batch_list))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Save trained model\n",
    "tokenizer.save_pretrained('../data/temp/1st_sent/test1.pt')\n",
    "model.save_pretrained('../data/temp/1st_sent/test1.pt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tests"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Reload trained model\n",
    "reload_model = BertForSequenceClassification.from_pretrained('../data/temp/1st_sent/test1.pt')\n",
    "tokenizer = BertTokenizer.from_pretrained('../data/temp/1st_sent/test1.pt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Validation check\n",
    "reload_model.to('cpu')\n",
    "reload_model.eval()\n",
    "eval_loss = 0\n",
    "eval_batch_num = 0\n",
    "eval_batch_list = [item for item in batch(valid_df, 16)]\n",
    "with torch.no_grad():\n",
    "    for batch_df in tqdm.tqdm(eval_batch_list):\n",
    "        labels = torch.tensor([1 if i == 'T' else 0 for i in batch_df.label.to_list()]).unsqueeze(1)\n",
    "        inputs = BatchEncoding(tokenizer(batch_df.sent.to_list(), batch_df.pair.to_list(), padding=True, truncation=True, max_length=80, return_tensors='pt'))\n",
    "        output = reload_model(**inputs, labels=labels)\n",
    "        eval_loss += output.loss\n",
    "    print(eval_loss / len(eval_batch_list))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Function that help generate score\n",
    "def get_score(sents:List[str], pairs:List[str]):\n",
    "    with torch.no_grad():\n",
    "        inputs = BatchEncoding(tokenizer(sents, pairs, padding=True, truncation=True, max_length=80, return_tensors='pt'))\n",
    "        output = reload_model(**inputs)\n",
    "        s = Softmax(1)\n",
    "        return s(output.logits)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get logits score\n",
    "val_output = get_score(valid_df.sent.to_list(), valid_df.pair.to_list())\n",
    "# Get prediction label\n",
    "cls_result = np.argmax(val_output.numpy(), axis=1)\n",
    "# Get prediction score\n",
    "cls_score = val_output.numpy()[:, 1]\n",
    "# Get ground truth\n",
    "val_label = np.array([1 if l == 'T' else 0 for l in valid_df.label.to_list()])\n",
    "# Get correct ones\n",
    "correct_prediction = val_label == cls_result\n",
    "# Sum the number of correct ones\n",
    "correct_num = np.sum(correct_prediction)\n",
    "# Get the wrong prediction idx\n",
    "wrong_prediction_idx = np.arange(0, len(val_label))[val_label != cls_result]\n",
    "# Get the wrong ones\n",
    "wrong_samples = [(cls_result[idx], valid_df.label[idx], valid_df.pair[idx], valid_df.sent[idx]) for idx in wrong_prediction_idx]\n",
    "# Write the wrong ones to file\n",
    "with open('../data/temp/1st_sent/wrong_prediction.tsv', 'w') as f_out:\n",
    "    w = csv.writer(f_out, delimiter='\\t')\n",
    "    w.writerows(wrong_samples)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# test_sents = my_read('all_occurance.txt')\n",
    "# test_pairs = ['<HEAD_ENT> %s <TAIL_ENT> %s' % ('python', 'programming language')] * len(test_sents)\n",
    "\n",
    "# test_result = get_score(test_sents, test_pairs)\n",
    "# test_cls_score = test_result.numpy()[:, 1]\n",
    "# test_idx = ntopidx(len(test_cls_score), test_cls_score)\n",
    "# test_sentences = [('%.8f' % test_cls_score[i], test_sents[i]) for i in test_idx]\n",
    "# with open('test.tsv', 'w') as f_out:\n",
    "#     w = csv.writer(f_out, delimiter='\\t')\n",
    "#     w.writerows(test_sentences)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5479462052bd6ecbded73107b69bede395ffae09f7ec13a4a64bf5809dc60a3f"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('FWD_pip': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}