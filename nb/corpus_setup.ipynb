{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "from tools.TextProcessing import sent_lemmatize, build_word_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process keyword file (20 seconds)\n",
    "\n",
    "filtered_words = set(['can', 'it', 'work', 'in', 'parts', 'is', 'its', 'or', 'and', 'a','b','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z', ''])\n",
    "\n",
    "stable_kw = []\n",
    "unstable_kw = []\n",
    "with open('../data/raw_data/keyword.csv', 'r') as f_in:\n",
    "    for line in f_in:\n",
    "        kw = line.split(',')[0]\n",
    "        if '- ' in kw:\n",
    "            continue\n",
    "        splited = kw.replace('-', ' - ')\n",
    "        reformed = ' '.join(sent_lemmatize(splited))\n",
    "        if reformed in filtered_words:\n",
    "            continue\n",
    "        if reformed == splited:\n",
    "            stable_kw.append(kw)\n",
    "        else:\n",
    "            unstable_kw.append('%s\\t%s' % (kw, reformed))\n",
    "\n",
    "with open('../data/corpus/keyword_f.txt', 'w') as f_out:\n",
    "    f_out.write('\\n'.join(stable_kw))\n",
    "\n",
    "with open('../data/temp/unstable_keyword.txt', 'w') as f_out:\n",
    "    f_out.write('\\n'.join(unstable_kw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check stable keywords\n",
    "'-' in stable_kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate word tree (25 seconds)\n",
    "build_word_tree('../data/corpus/keyword_f.txt', '../data/corpus/wordtree.json', '../data/corpus/entity.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sentence from small corpus (2 minute)\n",
    "j = json.load(open('../data/raw_data/small_arxiv.json', 'r'))\n",
    "sents = [i['abstract'].replace('\\n', ' ').strip() for i in j]\n",
    "with open('../data/corpus/pre_small_sent.txt', 'w') as f_out:\n",
    "    f_out.write('\\n'.join(sents))\n",
    "\n",
    "!sed 's/\\$//g;s/\\\\/ /g;s/---*/, /g;s/([^)]*)//g;s/{[^)]*}//g;s/-/ - /g' ../data/corpus/pre_small_sent.txt | tr -s [:space:] | tr '[:upper:]' '[:lower:]' > ../data/corpus/small_sent.txt\n",
    "\n",
    "!python ../py/sent_tokenize.py ../data/corpus/small_sent.txt ../data/corpus/small_sent.txt\n",
    "\n",
    "!rm ../data/corpus/pre_small_sent.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sentence from 1st_sents_new.json\n",
    "file_dir = '../data/raw_data/1st-sents-new.json'\n",
    "\n",
    "j = json.load(open(file_dir, 'r'))\n",
    "sents = [i['sentence'].strip() for i in j.values()]\n",
    "with open('../data/corpus/pre_1st_sent.txt', 'w') as f_out:\n",
    "    f_out.write('\\n'.join(sents))\n",
    "\n",
    "!sed 's/\\$//g;s/\\\\/ /g;s/---*/, /g;s/([^)]*)//g;s/{[^)]*}//g;s/-/ - /g' ../data/corpus/pre_1st_sent.txt | tr -s [:space:] | tr '[:upper:]' '[:lower:]' > ../data/corpus/1st_sent.txt\n",
    "\n",
    "!rm ../data/corpus/pre_1st_sent.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Reformed sentences (3 minutes)\n",
    "# To run the code in the backend, use the gen_reform.py in the \"py\" folder"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}