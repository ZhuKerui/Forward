{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "from tools.TextProcessing import nlp\n",
    "from tools.BasicUtils import my_write, my_read"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def find_dependency_path_from_tree(doc, kw1:spacy.tokens.span.Span, kw2:spacy.tokens.span.Span):\n",
    "    idx1 = kw1[-1].i\n",
    "    idx2 = kw2[-1].i\n",
    "    branch = np.zeros(len(doc))\n",
    "    i = idx1\n",
    "    while branch[i] == 0:\n",
    "        branch[i] = 1\n",
    "        i = doc[i].head.i\n",
    "    i = idx2\n",
    "    while branch[i] != 1:\n",
    "        branch[i] = 2\n",
    "        if i == doc[i].head.i:\n",
    "            return ''\n",
    "        i = doc[i].head.i\n",
    "    dep1 = []\n",
    "    j = idx1\n",
    "    while j != i:\n",
    "        dep1.append('i_%s' % doc[j].dep_)\n",
    "        j = doc[j].head.i\n",
    "    dep2 = []\n",
    "    j = idx2\n",
    "    while j != i:\n",
    "        dep2.append(doc[j].dep_)\n",
    "        j = doc[j].head.i\n",
    "    dep2.reverse()\n",
    "    if branch[idx2] == 1:\n",
    "        # kw2 is along the heads of kw1\n",
    "        return ' '.join(dep1)\n",
    "    elif i == idx1:\n",
    "        # kw1 is along the heads of kw2\n",
    "        return ' '.join(dep2)\n",
    "    else:\n",
    "        return ' '.join(dep1 + dep2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "p2line_dict = {}\n",
    "sents = my_read('temp_sent.txt')\n",
    "for i, line in enumerate(sents):\n",
    "    doc = nlp(line.strip())\n",
    "    l = [s for s in doc.noun_chunks if s[-1].pos_ != 'PRON']\n",
    "    if len(l) < 2:\n",
    "        continue\n",
    "    for j in range(len(l)-1):\n",
    "        for k in range(j, len(l)):\n",
    "            p = find_dependency_path_from_tree(doc, l[j], l[k])\n",
    "            if not p:\n",
    "                continue\n",
    "            if p not in p2line_dict:\n",
    "                p2line_dict[p] = []\n",
    "            p2line_dict[p].append({'kw1':str(l[j]), 'kw2':str(l[k]), 'line':i})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(p2line_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "freq_p = [k for k, c in p2line_dict.items() if len(c) > 10]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(freq_p)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "my_write('freq_path_10.txt', freq_p)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "p = 'prep pobj conj'\n",
    "my_write(p, ['%s\\t\\t%s\\t\\t%s' % (d['kw1'], d['kw2'], sents[d['line']]) for d in p2line_dict[p]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "s = 'many machine learning tools have been applied to this problem using static machine learning structures such as neural networks or svm that are unable to accommodate new information into their existing models.'\n",
    "doc = nlp(s)\n",
    "l = list(doc.noun_chunks)\n",
    "print(l)\n",
    "find_dependency_path_from_tree(doc, l[2], l[4])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "type(doc[0:2])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tools.BasicUtils import SparseRetrieveSentForPairCoOccur"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sparse_retriever = SparseRetrieveSentForPairCoOccur('../data/corpus/small_sent.txt', 'data/occur.json')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('FWD': conda)"
  },
  "interpreter": {
   "hash": "5e687002bc60377ae87b855adfe470e827b4be244d7382e97081511de02b6558"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}