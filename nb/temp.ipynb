{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from tools.TextProcessing import nlp, find_dependency_path_from_tree, find_span\n",
    "from tools.BasicUtils import my_write, my_read, SparseRetrieveSentForPairCoOccur"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def find_dependency_path_from_tree(doc, kw1:spacy.tokens.span.Span, kw2:spacy.tokens.span.Span):\n",
    "    idx1 = kw1[-1].i\n",
    "    idx2 = kw2[-1].i\n",
    "    branch = np.zeros(len(doc))\n",
    "    i = idx1\n",
    "    while branch[i] == 0:\n",
    "        branch[i] = 1\n",
    "        i = doc[i].head.i\n",
    "    i = idx2\n",
    "    while branch[i] != 1:\n",
    "        branch[i] = 2\n",
    "        if i == doc[i].head.i:\n",
    "            return ''\n",
    "        i = doc[i].head.i\n",
    "    dep1 = []\n",
    "    j = idx1\n",
    "    while j != i:\n",
    "        dep1.append('i_%s' % doc[j].dep_)\n",
    "        j = doc[j].head.i\n",
    "    dep2 = []\n",
    "    j = idx2\n",
    "    while j != i:\n",
    "        dep2.append(doc[j].dep_)\n",
    "        j = doc[j].head.i\n",
    "    dep2.reverse()\n",
    "    if branch[idx2] == 1:\n",
    "        # kw2 is along the heads of kw1\n",
    "        return ' '.join(dep1)\n",
    "    elif i == idx1:\n",
    "        # kw1 is along the heads of kw2\n",
    "        return ' '.join(dep2)\n",
    "    else:\n",
    "        return ' '.join(dep1 + dep2)\n",
    "\n",
    "def find_span(doc:spacy.tokens.doc.Doc, phrase:str, use_lemma:bool=False):\n",
    "    tokens = phrase.split()\n",
    "    match_started = False\n",
    "    pointer, start_idx, end_idx = 0, 0, 0\n",
    "    match_spans = []\n",
    "    for i in range(len(doc)):\n",
    "        present_token = str(doc[i].lemma_ if use_lemma else doc[i])\n",
    "        if present_token == tokens[pointer]:\n",
    "            if not match_started:\n",
    "                start_idx = i\n",
    "                match_started = True\n",
    "            pointer += 1\n",
    "            if pointer == len(tokens):\n",
    "                end_idx = i+1\n",
    "                match_spans.append((start_idx, end_idx))\n",
    "                pointer = 0\n",
    "                match_started = False\n",
    "        else:\n",
    "            pointer = 0\n",
    "            match_started = False\n",
    "    return match_spans\n",
    "\n",
    "def examine_sent(doc, path_set:set, kw1:str, kw2:str):\n",
    "    kw1_span = find_span(doc, kw1, True)\n",
    "    kw2_span = find_span(doc, kw2, True)\n",
    "    path = ''\n",
    "    for kw1_s, kw1_e in kw1_span:\n",
    "        for kw2_s, kw2_e in kw2_span:\n",
    "            path = find_dependency_path_from_tree(doc, doc[kw1_s:kw1_e], doc[kw2_s:kw2_e])\n",
    "            if path in path_set:\n",
    "                return path\n",
    "            path = ''\n",
    "    return path"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "p2line_dict = {}\n",
    "sents = my_read('data/temp_sents.txt')\n",
    "for i, line in enumerate(sents):\n",
    "    doc = nlp(line.strip())\n",
    "    l = [s for s in doc.noun_chunks if s[-1].pos_ != 'PRON']\n",
    "    if len(l) < 2:\n",
    "        continue\n",
    "    for j in range(len(l)-1):\n",
    "        for k in range(j, len(l)):\n",
    "            p = find_dependency_path_from_tree(doc, l[j], l[k])\n",
    "            if not p:\n",
    "                continue\n",
    "            if p not in p2line_dict:\n",
    "                p2line_dict[p] = []\n",
    "            p2line_dict[p].append({'kw1':str(l[j]), 'kw2':str(l[k]), 'line':i})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(p2line_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "freq_p = [k for k, c in p2line_dict.items() if len(c) > 10]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(freq_p)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "my_write('data/freq_path_10.txt', freq_p)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "p = 'prep pobj conj'\n",
    "my_write('data/'+p, ['%s\\t\\t%s\\t\\t%s' % (d['kw1'], d['kw2'], sents[d['line']]) for d in p2line_dict[p]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "s = 'our working database is the 5 - dimensional magnitude space of the sloan digital sky survey with more than 270 million data points, where we show that these techniques can dramatically speed up data mining operations such as finding similar objects by example, classifying objects or comparing extensive simulation sets with observations.'\n",
    "doc = nlp(s)\n",
    "l = list(doc.noun_chunks)\n",
    "print(l)\n",
    "find_dependency_path_from_tree(doc, l[0], l[3])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sparse_retriever = SparseRetrieveSentForPairCoOccur('../data/corpus/small_sent.txt', '../joint_score_func/data/occur.json')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "kw1 = 'database'\n",
    "kw2 = 'data mining'\n",
    "path_set = set(my_read('paths.txt'))\n",
    "sents = sparse_retriever.retrieve(kw1, kw2)\n",
    "df = pd.DataFrame({'sent':sents})\n",
    "df['doc'] = df.apply(lambda x: nlp(x['sent']), axis=1)\n",
    "df['path'] = df.apply(lambda x: examine_sent(x['doc'], path_set, kw1, kw2), axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df['path']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "my_write('temp.txt', sents)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "source": [
    "def exact_match(pattern:re.Pattern, path:str):\n",
    "    mat = pattern.match(path)\n",
    "    if mat is None:\n",
    "        return False\n",
    "    return len(path) == mat.end()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "source": [
    "patterns = ['i_nsubj attr( prep pobj)*', \n",
    "            'i_nsubj( conj)* dobj( acl prep pobj( conj)*){0,1}', \n",
    "            'i_nsubj( prep pobj)+', \n",
    "            'i_nsubj advcl dobj( acl attr){0,1}', \n",
    "            'appos( conj)*', \n",
    "            'appos acl prep pobj( conj)*', \n",
    "            'i_nsubjpass( conj)*( prep pobj)+( conj)*', \n",
    "            'i_nsubjpass prep pobj acl dobj', \n",
    "            '(i_dobj ){0,1}prep pobj( conj)*', \n",
    "            '(acl ){0,1}prep pobj( conj)*']\n",
    "matcher = re.compile('|'.join(patterns))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "source": [
    "exact_match(matcher, 'prep pobj conj conj')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 132
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('FWD': conda)"
  },
  "interpreter": {
   "hash": "5e687002bc60377ae87b855adfe470e827b4be244d7382e97081511de02b6558"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}