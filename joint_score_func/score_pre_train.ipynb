{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import json\n",
    "import csv\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import Softmax, Sigmoid, BCELoss\n",
    "import pandas\n",
    "from datasets import load_from_disk\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer, BatchEncoding, PreTrainedModel, PretrainedConfig, BertModel, BertConfig, AdamW, BartForConditionalGeneration, BartTokenizer\n",
    "import sys\n",
    "import tqdm\n",
    "\n",
    "sys.path.append('..')\n",
    "from tools.BasicUtils import ntopidx, SparseRetrieveSentForPairCoOccur"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1> Training test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Score function 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenizer.add_special_tokens({'additional_special_tokens' : ['<RELATION>']})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define dataset and training arguement\n",
    "dataset = load_from_disk('data/single-ollie')\n",
    "training_args = TrainingArguments(\"data/single-ollie-sf1\", evaluation_strategy=\"epoch\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load model\n",
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define data pre-process function and reform dataset\n",
    "def preprocess_sf1(examples):\n",
    "    # return BatchEncoding(tokenizer(examples['ent1'], examples['ent2'], padding=True, truncation=True, max_length=100, return_tensors=\"pt\"))\n",
    "    query = ['%s <RELATION> %s' % (ent1, ent2) for ent1, ent2 in zip(examples['ent1'], examples['ent2'])]\n",
    "    return tokenizer(query, examples[\"sent\"], padding=True, truncation=True, max_length=100)\n",
    "    \n",
    "train_dataset = dataset['train'].map(preprocess_sf1, batched=True)\n",
    "valid_dataset = dataset['valid'].map(preprocess_sf1, batched=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define trainer and do training\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=train_dataset, eval_dataset=valid_dataset)\n",
    "trainer.train()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Score function 2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenizer.add_special_tokens({'additional_special_tokens' : ['<RELATION>']})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define dataset and training arguement\n",
    "dataset = load_from_disk('data/single-ollie')\n",
    "training_args = TrainingArguments(\"data/single-ollie-sf2\", evaluation_strategy=\"epoch\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load model\n",
    "class ScoreFunction2(PreTrainedModel):\n",
    "    def __init__(self, config:PretrainedConfig):\n",
    "        super().__init__(config)\n",
    "        self._context_encoder = BertModel(config)\n",
    "        self._query_encoder = BertModel(config)\n",
    "        self._sigmoid = Sigmoid()\n",
    "\n",
    "    def forward(self, \n",
    "        context_input_ids,\n",
    "        query_input_ids,\n",
    "        context_token_type_ids=None,\n",
    "        context_attention_mask=None,\n",
    "        query_token_type_ids=None,\n",
    "        query_attention_mask=None):\n",
    "        context_inputs = {'input_ids': context_input_ids, 'token_type_ids': context_token_type_ids, 'attention_mask': context_attention_mask}\n",
    "        query_inputs = {'input_ids': query_input_ids, 'token_type_ids': query_token_type_ids, 'attention_mask': query_attention_mask}\n",
    "        context_emb = self._context_encoder(**context_inputs).last_hidden_state[:, 0, :]\n",
    "        query_emb = self._query_encoder(**query_inputs).last_hidden_state[:, 0, :]\n",
    "        score = self._sigmoid(torch.mul(context_emb, query_emb).sum(dim=1))\n",
    "        return score\n",
    "\n",
    "model = ScoreFunction2(BertConfig())\n",
    "model._query_encoder.resize_token_embeddings(len(tokenizer))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def preprocess_sf2(examples):\n",
    "    query = ['%s <RELATION> %s' % (ent1, ent2) for ent1, ent2 in zip(examples['ent1'], examples['ent2'])]\n",
    "    context_tokenized = tokenizer(examples[\"sent\"], padding=True, truncation=True, max_length=100)\n",
    "    query_tokenized = tokenizer(query, padding=True, truncation=True, max_length=100)\n",
    "    return {'context_input_ids': context_tokenized['input_ids'], \n",
    "            'context_token_type_ids': context_tokenized['token_type_ids'], \n",
    "            'context_attention_mask': context_tokenized['attention_mask'],\n",
    "            'query_input_ids': query_tokenized['input_ids'], \n",
    "            'query_token_type_ids': query_tokenized['token_type_ids'], \n",
    "            'query_attention_mask': query_tokenized['attention_mask']}\n",
    "\n",
    "train_dataset = dataset['train'].map(preprocess_sf2, batched=True)\n",
    "valid_dataset = dataset['valid'].map(preprocess_sf2, batched=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class ScoreFunction2Trainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        loss_function = BCELoss()\n",
    "        loss = loss_function(outputs, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "        \n",
    "trainer = ScoreFunction2Trainer(model=model, args=training_args, train_dataset=train_dataset, eval_dataset=valid_dataset)\n",
    "trainer.train()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> Temp"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "temp_dict = json.load(open('data/my_dataset.json'))\n",
    "temp_dict['train'] = temp_dict['train'][:10000]\n",
    "temp_dict['valid'] = temp_dict['valid'][:2000]\n",
    "train_dataset = pandas.DataFrame.from_dict(temp_dict['train'])\n",
    "valid_dataset = pandas.DataFrame.from_dict(temp_dict['valid'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tools.BasicUtils import batch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "device = torch.device('cuda')\n",
    "def preprocess_sf2_temp(examples):\n",
    "    query = ['%s <RELATION> %s' % (ent1, ent2) for ent1, ent2 in zip(examples['ent1'], examples['ent2'])]\n",
    "    context_tokenized = tokenizer(examples[\"sent\"].to_list(), padding=True, truncation=True, max_length=100)\n",
    "    query_tokenized = tokenizer(query, padding=True, truncation=True, max_length=100)\n",
    "    return {'context_input_ids': torch.LongTensor(context_tokenized['input_ids']).to(device), \n",
    "            'context_token_type_ids': torch.LongTensor(context_tokenized['token_type_ids']).to(device), \n",
    "            'context_attention_mask': torch.LongTensor(context_tokenized['attention_mask']).to(device),\n",
    "            'query_input_ids': torch.LongTensor(query_tokenized['input_ids']).to(device), \n",
    "            'query_token_type_ids': torch.LongTensor(query_tokenized['token_type_ids']).to(device), \n",
    "            'query_attention_mask': torch.LongTensor(query_tokenized['attention_mask']).to(device),\n",
    "            'labels' : torch.Tensor(examples['labels'].to_list()).to(device)}\n",
    "\n",
    "def compute_loss(model, inputs, return_outputs=False):\n",
    "    labels = inputs.pop('labels')\n",
    "    outputs = model(**inputs)\n",
    "    loss_function = BCELoss()\n",
    "    loss = loss_function(outputs, labels)\n",
    "    return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "model.to(device)\n",
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "for epoch in range(3):\n",
    "    loss_sum = 0\n",
    "    i = 0\n",
    "    batch_list = [item for item in batch(train_dataset, 16)]\n",
    "    for i, b in enumerate(tqdm.tqdm(batch_list)):\n",
    "        inputs = preprocess_sf2_temp(b)\n",
    "        loss = compute_loss(model, inputs)\n",
    "        loss.backward()\n",
    "        loss_sum += loss.detach()\n",
    "        optim.step()\n",
    "    print(loss_sum / (i + 1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.save_pretrained('data/single-ollie-temp')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Score function 3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "tokenizer.add_special_tokens({'additional_special_tokens' : ['<ENT1>', '<ENT2>', '<RELATION>']})"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Define dataset and training arguement\n",
    "dataset = load_from_disk('data/single-ollie-pos-only')\n",
    "training_args = TrainingArguments(\"data/single-ollie-sf3\", evaluation_strategy=\"epoch\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Load model\n",
    "relation_extractor = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
    "relation_extractor.resize_token_embeddings(len(tokenizer))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Embedding(50268, 768)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def preprocess_sf3(examples):\n",
    "    conditions = ['%s <ENT1> %s <ENT2> %s' % (sent, ent1, ent2) for ent1, ent2, sent in zip(examples['ent1'], examples['ent2'], examples['sent'])]\n",
    "    rel_tokenized = tokenizer(examples[\"sent\"], padding='max_length', truncation=True, max_length=100)\n",
    "    condition_tokenized = tokenizer(conditions, padding='max_length', truncation=True, max_length=100)\n",
    "    return {'input_ids': condition_tokenized['input_ids'],\n",
    "            'labels' : rel_tokenized['input_ids']}\n",
    "\n",
    "train_dataset = dataset['train'].map(preprocess_sf3, batched=True)\n",
    "valid_dataset = dataset['valid'].map(preprocess_sf3, batched=True)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de74766858404ec58b1a141ab9e77c56"
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=221.0), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1ad1dfaedb8d439190c3027cf3eed0d5"
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25.0), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Define trainer and do training\n",
    "trainer = Trainer(model=relation_extractor, args=training_args, train_dataset=train_dataset, eval_dataset=valid_dataset)\n",
    "trainer.train()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: ent1, ent2, sent, rel.\n",
      "***** Running training *****\n",
      "  Num examples = 220986\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 82872\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='414' max='82872' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  414/82872 01:05 < 3:38:04, 6.30 it/s, Epoch 0.01/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-010f56740fda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Define trainer and do training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelation_extractor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/FWD/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1306\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m                             \u001b[0;31m# Revert to normal clipping otherwise, handling Apex or full precision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m                             nn.utils.clip_grad_norm_(\n\u001b[0m\u001b[1;32m   1309\u001b[0m                                 \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaster_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_apex\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m                                 \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/FWD/lib/python3.9/site-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror_if_nonfinite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             raise RuntimeError(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1> Testing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('data/single-ollie/checkpoint-3500')\n",
    "# model = ScoreFunction2.from_pretrained('data/single-ollie2')\n",
    "model.eval()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sparse_retriever = SparseRetrieveSentForPairCoOccur('../data/corpus/small_sent.txt', 'data/occur.json')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ent1 = 'data mining'\n",
    "ent2 = 'machine learning'\n",
    "s = 'in this paper, we show that by using the fuzzy statistics analysis and the data mining technology, the target - oriented fuzzy correlation rules can be obtained from a given database.'\n",
    "# sent = sparse_retriever.retrieve(ent1, ent2)\n",
    "# test_list = [{'sent' : s, 'ent1' : ent1, 'ent2' : ent2, 'labels' : 1} for s in sent]\n",
    "test_list = [{'sent' : s, 'ent1' : ent1, 'ent2' : ent2, 'labels' : 1}]\n",
    "print(len(test_list))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "temp_dict = json.load(open('data/my_dataset.json'))\n",
    "test_list = temp_dict['valid'][:200]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "valid_df = pandas.DataFrame.from_dict(test_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Function that help generate score\n",
    "def get_score(sents:List[str], ent1s:List[str], ent2s:List[str]):\n",
    "    query = ['%s <RELATION> %s' % (ent1, ent2) for ent1, ent2 in zip(ent1s, ent2s)]\n",
    "    with torch.no_grad():\n",
    "        inputs = BatchEncoding(tokenizer(query, sents, padding=True, truncation=True, max_length=80, return_tensors='pt'))\n",
    "        output = model(**inputs)\n",
    "        s = Softmax(1)\n",
    "        return s(output.logits)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get logits score\n",
    "val_output = get_score(valid_df.sent.to_list(), valid_df.ent1.to_list(), valid_df.ent2.to_list())\n",
    "# Get prediction label\n",
    "cls_result = np.argmax(val_output.numpy(), axis=1)\n",
    "# Get prediction score\n",
    "cls_score = val_output.numpy()[:, 1]\n",
    "# Get ground truth\n",
    "val_label = np.array(valid_df.labels.to_list())\n",
    "# Get correct ones\n",
    "correct_prediction = val_label == cls_result\n",
    "# Sum the number of correct ones\n",
    "correct_num = np.sum(correct_prediction)\n",
    "# Get the wrong prediction idx\n",
    "wrong_prediction_idx = np.arange(0, len(val_label))[val_label != cls_result]\n",
    "# Get the wrong ones\n",
    "wrong_samples = [(cls_result[idx], valid_df.labels[idx], valid_df.ent1[idx], valid_df.ent2[idx], valid_df.sent[idx]) for idx in wrong_prediction_idx]\n",
    "# Write the wrong ones to file\n",
    "with open('data/wrong_prediction.tsv', 'w') as f_out:\n",
    "    w = csv.writer(f_out, delimiter='\\t')\n",
    "    w.writerows(wrong_samples)\n",
    "\n",
    "# Get rank\n",
    "rank_ids = ntopidx(len(cls_score), cls_score)\n",
    "rank_list = [(cls_score[idx], valid_df.ent1[idx], valid_df.ent2[idx], valid_df.sent[idx]) for idx in rank_ids]\n",
    "with open('data/rank_list.tsv', 'w') as f_out:\n",
    "    w = csv.writer(f_out, delimiter='\\t')\n",
    "    w.writerows(rank_list)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('FWD': conda)"
  },
  "interpreter": {
   "hash": "5e687002bc60377ae87b855adfe470e827b4be244d7382e97081511de02b6558"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}